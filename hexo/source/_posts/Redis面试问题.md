---
title: Redis面试问题
tags:
  - Java后端面试
  - Redis
  - 分布式锁
categories:
  - Java后端面试
date: '2020-4-28 21:56'
image: 'https://gitee.com/jingshanccc/image/raw/master/image/20200722004924.jpg'
abbrlink: e745ac01
---

<p>
<!-- more -->

## 为什么要使用缓存？

1. 高性能

   假设用户第一次访问数据库获取数据，这个过程是比较慢的，因为是从硬盘读取，同时如果需要获取的数据本身计算过程十分耗时，那么我们将第一次获取到的结果直接放在缓存中，下一次访问直接在缓存中获取即可，操作缓存就是操作内存，速度更块。

2. 高并发

   内存能够承受的请求是远远大于直接访问数据库的，所以我们将数据库的部分数据转移到缓存中，可以让部分请求直接访问内存而不经过数据库。

<details>
<summary>数据库有缓存吗？</summary>
有，以mysql为例，它会将查询sql和结果以key-value的形式缓存起来，再遇到hash值相同的sql语句就不再经过编译解析优化和查询，直接返回结果。<br/>
缺点：
    通过hash，意味着语义相同的可能有不同的表达，这样也无法命中缓存。对于频繁更新的表，缓存总是难以命中，但还是需要耗费资源维护缓存。
</details>

## 选择Redis的原因？

### 本地缓存和分布式缓存

1. Java中使用map/guaua来做本地缓存，直接将数据存在jvm内存中，与jvm拥有相同的生命周期。其优点是轻量且快速。但在多实例的情况下，每个实例都需要保存自己的一份缓存，不具有一致性

2. Redis和Memcache实现的是分布式缓存，在多实例下，共用一份缓存，具有一致性。因此需要保证服务的高可用，架构较复杂。

### redis和memcache

1. 持久化：memcache不支持持久化，缓存数据只存在在内存中，断电后数据就丢失了。redis提供了持久化机制，可以将数据保存到磁盘中，重启后通过日志文件可以恢复数据。
2. 数据类型：memcache只支持简单的string类型，redis除了string之外，还支持列表，哈希，集合等多种数据结构。
3. 分布式：memcache不支持分布式，只能通过多个客户端使用一致性哈希来向集群中存储数据，这种方式在查询和存储时都需要计算一次。redis原生支持集群模式。
4. 线程模型：memcache是多线程的，redis默认是单线程的，减少了线程切换的消耗

## 说说Redis的线程模型？

redis内部采用文件事件处理器，它是单线程的，通过I/O多路复用机制，监听多个socket，根据socket上的事件选择对应的事件处理器来处理。
文件事件处理器包括四个部分：socket、I/O多路复用程序、事件分派器、事件处理器（包括连接应答处理器，命令请求处理器，命令回复处理器）

redis基于reactor模式开发出自己的I/O多路复用程序，多个socket同时产生的事件将被加入到队列中，事件分派器从队列中取出事件，根据事件类型分派给不同的事件处理器。

<details><summary>事件的调度和执行</summary>
redis服务器是一个事件驱动程序，有文件事件和时间事件。服务器需要一直监听socket以得到到达的文件事件，但是由于需要执行时间事件，不能一直监听，否则时间事件不能在预期时间内执行。因此，redis通过计算距离最近的时间事件，根据所剩的时间，监听文件事件，在剩余时间结束后，处理该时间段内的文件事件，同时处理该时间的时间事件。不断重复直到服务器关闭。
</details>

## 你了解Redis的数据类型吗？应用场景是什么？

1. String字符串

   存储：字符串，整型，浮点型

   命令：set get incr decr

   应用场景：key-value存储，计数器

   底层实现：简单可变字符串，使用char数组保存数据，并有长度len，空闲长度free。记录len和free属性可以实现空间预分配和惰性释放。通过len减少连续增长字符串时所需的空间重分配的操作次数，因为每次增长字符串时将多分配len字节的未使用空间。通过free优化字符串的缩短操作，不需要在每次缩短时立即释放未使用的空间，通过free记录下来等待将来使用

2. List列表

   存储：列表

   命令：lpop lpush rpop rpush lrange(实现分页查询)

   应用场景：关注列表/粉丝列表/消息列表

   底层实现：结构体包含链表头节点、尾节点、长度、释放/复制/比较节点函数。节点数据结构包含前置/后置指针、任意类型的值。

3. Set集合

   存储：集合，去重

   命令：sadd spop smembers sunion

   应用场景：由于有方便的求交集差集并集的操作，可以实现共同关注等

   底层实现：使用整形集合或字典实现。

   ​    **整型集合**：当集合只包含int类型时，使用intset存放，intset数据结构中包含编码格式、数组、长度。编码格式规定了能存储的数据范围，比如int_16t表示存储-32768-32767（1位符号位15位数值位），超出范围则会自动升级到32位。

   ​    **字典**：Dict是最上层的结构体，包含两个dictht哈希表（一个用于存放数据一个用于rehash）、rehashidx、类型特定函数（键值复制释放、哈希函数、键比较函数）。dictht哈希表包含dictEntry数组、表的大小、已用大小、计算索引的sizemark。dictEntry结构体是数组中存放的数据类型，包含key、value、next指针。

4. Hash映射表

   存储：包含键值对的无序散列表

   命令：hset hget hexists hlen

   应用场景：存储结构化的对象 非常方便的修改某个属性

   底层实现：使用字典或压缩列表实现。

   ​    **字典**。

   ​    **压缩列表**：结构体中包含所占字节数zlbytes、尾部到起点的字节数zltail、节点数zllen、列表末端zlend、节点数组entry。节点结构体包含的属性有前一个结点的长度previous_length、数据类型encoding、数据内容content。存放hash对象时，键一个entry值一个entry

5. SortedSet有序集合

   存储：跟set相比，增加了权重参数，根据参数来排序

   命令：zadd zrange zrem zrank zcount

   应用场景：由于是排序的，可以实现排行榜等

   底层实现：使用跳跃表和字典来实现。**跳跃表**：基于链表+索引实现，解决了数组插入时的O(n),链表查询时的O(n)。由多层链表组成，每一层都是有序链表，上一层的链表是下一层链表的子集。每一个链表结点都有两个指针，一个指向同层的下一个结点，另一个指向下一层的同一个链表节点。最上层结构体是zskiplist，包含头节点和尾节点skiplistNode、节点数量length、最大层数level。

## Redis中Key的过期时间是怎么实现的？

通过set key的expiretime来设置key的存活时间，过期自动删除。redis中有两种key的过期机制。

- 定期删除：默认每100ms**随机抽取**内存中的key判断是否过期决定是否删除。可以在配置文件中设置间隔时间。定期删除每次不会检查所有key，因为这样会十分耗时，因此采用随机选择部分key进行判断。
- 惰性删除：因为定期删除可能遗漏了部分key，惰性删除则在key**再次被请求**时，判断是否过期决定是否删除。

但是在这两种过期机制下，还是会存在key到期也没被删除，定期删除没有删掉，惰性删除因为没有再次请求也没有生效，此时可能内存占用会越来越高。redis通过设置**内存淘汰策略**解决这一问题。

### 内存淘汰策略

当内存超过了设置的最大内存限制，就会执行内存淘汰策略。

1. allkeys-lru:从所有数据集中选择最近最久未使用的数据淘汰
2. allkeys-lfu:从所有数据集中选择访问频率最低的数据淘汰
3. allkeys-random:从所有数据集中随机选择数据淘汰
4. no-eviction：不淘汰，新写入时报错
5. volatile-lru:从已设置过期时间的数据集中选择最近最久未使用的数据淘汰
6. volatile-lfu:从已设置过期时间的数据集中选择访问频率最低的数据淘汰
7. volatile-ttl:从已设置过期时间的数据集中选择将要过期的数据淘汰
8. volatile-random:从已设置过期时间的数据集中随机选择数据淘汰

lru：redis中的lru不使用常规的维护队列的方式，通过全局的时钟和key中保存的时钟，选择最久未被使用的淘汰。一般场景下，缓存中存放热点数据，为了提高缓存命中率，使用lru策略
lfu：将lru中的24位时钟分为两部分，前16位记录时钟，后8位记录访问频率。访问频率并不是简单的线性增长，而是设置参数lfu-log-factor和lfu-decay-time通过公式来计算实现。

*当数据集中没有设置过期时间的key，前四种策略将由于不满足先决条件而和no-eviction相同*

## redis断电之后数据如何恢复？

通过redis的持久化机制，在重启之后可以恢复数据。redis提供了以下三种持久化机制。

- RDB快照持久化：将某一时刻的数据保存到文件中，通过配置文件可以设置在n秒内如果数据发生m次变化则触发bgsave创建快照，备份当前数据。也可以手动调用bgsave来触发持久化。在通过shutdown指令正常关闭时，如果没有开启aof，则会进行一次rdb持久化。rdb持久化的优点是文件小，恢复快。缺点是实时性较差，最后一次快照之后的数据将丢失。
- AOF持久化：开启了aof持久化后，redis将把每一条改变数据的操作追加到日志文件中。这样的缺点是aof文件会不断增大，可以通过日志重写来解决，日志重写的过程将当前数据直接生成新的命令写入到新的aof文件中，合并和简化命令。
- 混合持久化：开启混合持久化后，aof重写时将当前数据以rdb格式写入到文件，在此过程中新的变化将以aof格式写入，恢复时先将重写rdb内容，再执行aof的内容。

## 了解redis的事务吗？

redis事务通过MULTI、EXEC、DISCARD、WATCH来实现。只有在将命令添加进队列时发现语法错误才会导致EXEC命令报错。语法正确的指令即使是执行时出错，redis也会执行其他命令。

- MULTI:开启一个事务，之后可以一条条输入想要执行的命令添加到队列中
- EXEC:执行在MULTI之后队列中添加的所有命令
- DISCARD:回滚，取消执行MULTI开启的事务
- WATCH:监控一个或多个key，当key发生变化时，事务将不会被执行。提供了CAS的功能，在MULTI开始之前，监控key，EXEC时判断key是否修改过。

## 说说缓存穿透和缓存雪崩

- 缓存穿透：用户请求的数据不在数据库中，自然也不在缓存中，此时每次请求该key，总是无法在缓存中找到，也无法在数据库中找到。因此每次都会访问数据库。这种现象称为缓存穿透。

   **解决方法**：1. 为该key设置null值，但是设置较短的过期时间，避免当数据存在时却在缓存中获取到空值。2. 使用布隆过滤器，将所有可能存在的数据哈希到一个bitmap中，不存在的数据一定会被bitmap拦截。

- 缓存雪崩：大量的key在同一时间失效，导致请求全部落在数据库。

     **解决办法**：1. 预防：错开过期时间 2. 应对：限流以保证数据库不会挂掉

{% fold 缓存击穿 %}

一个热点数据在失效瞬间，仍然有大量请求来获取，此时缓存失效，请求都落在数据库上。

**解决方法**：1. 热点数据永不过期 2. 使用互斥锁：在请求时先查缓存，有则返回，否则尝试获取锁，成功之后查询数据库并更新缓存然后释放锁，获取锁失败说明已经有线程在查数据库准备更新缓存，因此可以通过自旋之后重试查询缓存。

{% endfold %}

{% fold 布隆过滤器 %}

单个hash函数可能出现不同数据hash值相同的情况，因此通过采用k个相互独立的hash函数解决冲突，将所有可能存在的数据hash到一个bitmap中。

{% endfold %}




## 如何解决并发竞争key问题？

多个客户端对同一个key做set操作。
解决方案：

1. 乐观锁：通过watch可以方便的实现乐观锁，watch监听的key在事务期间发生变化，事务将会回滚
2. 时间戳：在set key时加入时间戳，通过比较key的时间戳来确定是否继续执行set操作
3. 消息队列：将并发的操作加入到消息队列中，串行化执行
4. 分布式锁：客户端在执行操作之前需要先获取分布式锁

### 分布式锁的实现

> 分布式锁是控制分布式系统之间同步访问共享资源的方式。在分布式系统中，多个系统共享一个资源，使用分布式锁来保证数据一致性

#### 单实例

{% note info %}

使用set lock_key random_value nx px n完成加锁（一次原子性的setnx+expire），解锁时先get根据random_value判断是否是锁的拥有者，再进行del。为了保证原子性，使用lua脚本.

{% endnote %}

{% note info %}

使用redisson实现，方法1的实现锁不具有可重入性。redisson加解锁过程如下：

1. 加锁：通过tryAcquire来获取锁，如果返回的ttl为空表示加锁成功。加锁失败则会订阅该锁的channel，等待锁被释放的消息，再重新获取锁。tryAcquire中使用lua脚本来加锁，锁使用hash结构来实现。hexists判断锁是否存在，不存在则hset加锁成功，存在则判断是否是当前线程的锁，是则hincrby将count+1（可重入锁），否则返回锁的过期时间。
2. 解锁：同样使用lua脚本。先判断锁是否存在，不存在则publish发布释放锁的消息，解锁成功。锁存在则判断是否是当前线程的锁，如果是通过hincrby将count-1，当count为0，将del锁并publish释放锁的消息，如果不是则抛出异常。

{% endnote %}

#### 多实例

{% note info %}

redlock算法：根据[redis官网](http://redis.cn/topics/distlock.html/)描述总结。假定有5个redis实例，且相互独立，没有主从关系（原因是防止master节点没来得及把新set的锁复制到slave上）。

1. 尝试向五个实例获取锁
2. 超过获取锁的限制时间则跳到下一个实例
3. 超过半数（这里是3个）成功加锁并且消耗的总时间小于锁的过期时间则加锁成功
4. 加锁失败/释放锁，将向**所有实例**发出解锁请求。因为可能存在某个节点set成功但是由于网络问题客户端没有接收到其响应，因此需要向所有节点发出解锁请求
5. redlock采用**延时重启**来解决故障重启后带来的安全性问题：A B C三个节点，客户端1请求加锁在A B上获得成功，1获取锁。然后B宕机重启，由于持久化策略等问题，导致B上的锁没有被恢复，此时客户端2请求相同的锁，在BC上获取成功，这样客户端1和2就持有了相同的锁。

{% endnote %}

{% note info %}

zookeeper：客户端每次请求一把锁，就在zookeeper对应节点目录下创建一个有序节点，只需要比较节点的顺序就可以判断是否成功获取锁。

{% endnote %}

## redis单点/单机会有什么问题/挂掉怎么办？

为了避免redis单机挂掉的问题，我们可以搭建redis集群来保证redis服务的高可用。redis集群有以下三种模式：

1. 主从模式：实现读写分离，主节点的数据通过全量/增量同步发送到从节点上

2. 哨兵模式：主从模式升级版，哨兵监听主节点的状态，发现宕机后选出新的主节点

3. 集群模式：一个redis cluster由多个redis节点组组成，每个节点组内由主从节点，负责数据的一个/多个分片-slot。

{% note info %}

**配置的一致性**：集群中的每个节点都保存了集群的配置信息，通过一个全局的版本号epoch来保证信息的一致。各节点之间通过频繁的ping/pong消息携带的gossip部分更新自己对集群的认识。当某个节点率先感知了集群的变化后，自增自身的epoch并将其通过ping/pong消息扩散出去，其他节点发现接收到的epoch＞自身于是更新自身关于集群的信息。

**数据分片**：cluster中节点组之间负责的数据互相独立，客户端需要通过一致性哈希算法将key映射到0-16383个slot中的一个上，找到对应的redis节点。当请求的key不在节点上（发生了数据迁移），会返回moved/ask消息告知客户端.

**Failover保证高可用**：故障发现、故障确认、主备切换机制

1. 故障发现：各节点在进行ping/pong交换信息时，如果一个节点A的ping消息超时没有收到对端B的pong回复，则会在自身集群信息中将该节点状态设置为pfail，并通过和其他节点的ping/pong将此信息传递到整个集群。

2. 故障确认：节点A在1之后，如果接收到其他节点的gossip消息中B也为pfail状态，则会将B的状态升级为fail，确认故障，然后发起slave选举流程。

3. slave选举：A作为B的salve在确认B为故障节点后，发起竞选：将自己的epoch自增并发送FAILOVER_AUTH_REQUEST到其他的master节点，如果master未收到过FAILOVER_AUTH_REQUEST(收到时的自身epoch小于FAILOVER_AUTH_REQUEST中的epoch)，则回复同意，否则拒绝。当A收到超过半数的master同意之后，将替代B称为master节点，更新自己的epoch，通过配置一致性完成集群结构的更新。当B回复正常后，通过与其他节点的gossip消息可以得知新的master节点为A，自己将会成为A的slave节点。

{% endnote %}

<details><summary>数据迁移</summary>
    当加入新的master节点/ 旧的节点组下线/负载不均衡需要调整时，会发生数据迁移，迁移过程：<br/>
    1. 设置slot原所在节点A状态为migrating,slot新节点B状态为importing.<br/>
    2. 针对A上的slot的所有key，分别发送migrate命令将数据迁移到B.<br/>
    migrating的A：如果请求的key尚未迁出则正常提供服务；如果已经迁出则使用ask回复让客户端跳转到B.<br/>
    importing的B：如果请求不是由ask跳转的则通过moved让客户端跳转到A上.<br/>
    这样的跳转控制可以让同一个key操作迁移之前在原节点执行，迁移之后在新节点执行，避免冲突。迁移完成之后，通过配置的一致性让整个集群更新配置。
</details>

<details><summary>moved和ask</summary>moved会更新client的路由缓存，即moved之后对相同的key操作会直接到新节点上，ask操作只是单次的，之后相同的key还是回到原来的节点上</details>

## 如何保证缓存和数据库的一致性？

如果要求数据库和缓存的实时一致性，那么只能串行化地执行读写请求。一般来说允许缓存和数据库出现短暂的不一致。最经典的方式是先更新数据库，再删除缓存。读请求先查缓存，缓存没有则查询数据库，将查询结果放入缓存中，返回响应。更新时，先更新数据库，再删除缓存。

### 为什么是删除缓存，而不是更新缓存？

在复杂一点的缓存场景中，缓存中的数据并不是简单的从数据库中直接获取。存入缓存的数据可能需要进行多表查询并进行计算得到。所以更新缓存的成本是比较高的。除此之外，缓存的数据如果来自一张频繁更新的表，但是缓存却较少的被访问，也会造成资源的浪费。因此采用删除缓存，是一种懒加载的思想，等到需要的时候发现缓存中没有再查询数据库将结果放入缓存。

### 先更新数据库再删除缓存就一定能保证一致性吗？

不一定，在更新完数据库之后，如果删除缓存失败，此时缓存中是旧的数据，而数据库是新的数据，出现了不一致。解决方法是：先删除缓存，再更新数据库。如果更新数据库失败了，再次请求则会去读取旧的数据，不会产生数据不一致。

### 这样就没问题了吗？

如果在并发量较低的情况下，一般不会出现问题。但是当并发量较大，对一个数据并发读写就可能出现：如果在删除完缓存之后，尚未完成更新，此时另一个请求到来，发现没缓存，于是查数据库，存入缓存，并返回结果。之后数据库完成了更新，此时数据库和缓存再次出现不一致。**解决方案**：串行化。一个更新数据的操作，“删除缓存+更新数据库”，将其路由到一个jvm的队列中。读取数据的操作，如果发现缓存中没有数据，则将“读取数据+更新缓存”的操作也放入一个jvm的工作队列中。一个工作线程对应一个队列，线程从队列中获取操作并执行，这样，更新数据的操作将顺序执行删除缓存，然后更新数据库，在数据库未更新完成之前，如果有读取数据的请求，发现缓存中没有数据，将进入工作队列中，等待前一个更新操作完成之后，再执行“读取数据+更新缓存”的操作，保证了数据的一致性。