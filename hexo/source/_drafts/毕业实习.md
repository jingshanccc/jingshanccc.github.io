---
abbrlink: 2930aaf7
---
## Hadoop安装

### 配置文件

1. 环境变量配置：修改/hadoop/etc/hadoop/hadoop-env.sh，配置JAVA_HOME

2. 公共属性配置：/hadoop/etc/hadoop/core-site.xml的configuration节点

   ```xml
   <configuration>
   	<!-- 指定 HADOOP 所使用的文件系统 schema （ URI ）， HDFS 的老大（ NameNode ）的地址 -->
       <property>
           <name>fs.defaultFS</name>
           <value>hdfs://master:9000</value>
       </property>
       <!-- 指定 hadoop 运行时产生文件的存储目录 -->
       <property>
           <name>hadoop.tmp.dir</name>
           <value>/usr/local/hadoop-3.2.1/tmpdata</value>
       </property>
   </configuration>
   ```

   

3. HDFS配置：修改hdfs-site.xml，添加副本、通讯等配置

   ```xml
   <configuration>
       <!-- 指定 HDFS 副本的数量 -->
       <property>
           <name>dfs.replication</name>
           <value>2</value>
       </property>
       <!-- 设置 namenode 的 http 通讯地址 -->
       <property>
           <name>dfs.namenode.http-address</name>
           <value>master:50070</value>
       </property>
       <!-- 设置 secondarynamenode 的 http 通讯地址 -->
       <property>
           <name>dfs.namenode.secondary.http-address</name>
           <value>master:50090</value>
       </property>
       <!-- 设置 namenode 存放的路径 -->
       <property>
           <name>dfs.namenode.name.dir</name>
           <value>/usr/local/hadoop-3.2.1/namenode</value>
       </property>
       <!-- 设置 datanode 存放的路径 -->
       <property>
           <name>dfs.datanode.data.dir</name>
           <value>/usr/local/hadoop-3.2.1/datanode</value>
       </property>
   </configuration>
   ```

   

4. MapReduce配置：修改 mapred-site.xml

   ```xml
   <configuration>
   	<!-- 指定 mr 运行在 yarn 上 -->
       <property>
           <name>mapreduce.framework.name</name>
           <value>yarn</value>
       </property>
       <property>
           <name>yarn.app.mapreduce.am.env</name>
           <value>HADOOP_MAPRED_HOME=/usr/local/hadoop-3.2.1</value>
       </property>
       <property>
           <name>mapreduce.map.env</name>
           <value>HADOOP_MAPRED_HOME=/usr/local/hadoop-3.2.1</value>
       </property>
       <property>
           <name>mapreduce.reduce.env</name>
           <value>HADOOP_MAPRED_HOME=/usr/local/hadoop-3.2.1</value>
       </property>
   </configuration>
   ```

   

5. YARN配置：修改 yarn-site.xml

   ```xml
   <configuration>
       <!-- 指定 YARN 的老大（ ResourceManager ）的地址 -->
       <property>
           <name>yarn.resourcemanager.hostname</name>
           <value>master</value>
       </property>
       <!-- reducer 获取数据的方式 -->
       <property>
           <name>yarn.nodemanager.aux-services</name>
           <value>mapreduce_shuffle</value>
       </property>
   </configuration>
   ```

   

6. datanode节点声明：workers配置

   ```bash
   vim workers
   slave01
   slave02
   ```

7. 修改环境变量

   ```bash
   vim /etc/profile
   # 增加
   export HADOOP_HOME=/usr/local/hadoop-3.2.1
   # 增加
   export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
   
   source /etc/profile
   ```

   

8. 通过scp复制到其他的worker节点

   ```bash
   scp -r /usr/local/hadoop-3.2.1/ root@slave01:/usr/local/
   scp /etc/profile root@slave01:/etc/
   ```

   

9. 格式化namenode

   ```bash
   hadoop namenode -format
   ```

   

10. 启动

    ```bash
    # 如果 HDFS 分布式文件系统与 Yarn 同时启动，停止 stop-all.sh
    start-all.sh
    # 单独启动：
    # 启动 HDFS 分布式文件系统 ，停止 stop-dfs.sh
    start-dfs.sh
    # 启动 Yarn 资源管理器，停止 stop-yarn.sh
    start-yarn.sh
    # 启动完成后可通过jps查看进程
    jps
    ```

    root用户可能启动报用户未指定异常

    ![image-20200722110318881](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200722110318881.png)

    通过修改env.sh指定用户

    ```bash
    export HDFS_NAMENODE_USER=root
    export HDFS_DATANODE_USER=root
    export HDFS_SECONDARYNAMENODE_USER=root
    export YARN_RESOURCEMANAGER_USER=root
    export YARN_NODEMANAGER_USER=root
    ```

    

### 基本命令

| 命令                             | 说明           |
| -------------------------------- | -------------- |
| hdfs dfs -ls /                   | 查看目录       |
| hdfs dfs -mkdir /xxx             | 创建目录       |
| hdfs dfs -put xx.txt /path       | 上传文件到hdfs |
| hdfs dfs -get /xx.txt /localPath | 下载到本地     |
| hdfs dfs -cat /xx.txt            | 查看文件内容   |
| hadoop dfs -rm -r /path          | 删除文件夹     |

## Spark安装

### 安装Scala语言

1. 解压，移动到目标目录

   ```bash
   tar -zxvf scala-2.11.0.tgz
   ```

2. 增加环境变量

   ```bash
   vi /etc/profile
   export SCALA_HOME=/usr/local/scala-2.11.0
   export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$SCALA_HOME/bin
   ```

   

3. 复制到其他slave

   ```bash
   scp -r scala-2.11.0 root@slave01:/xxx
   
   scp /etc/profile root@slave01:/etc/
   ```

   

### Spark组件安装

1. 解压，移动到目标目录

2. 修改配置文件 /spark/conf/spark-env.sh

   ```bash
   export JAVA_HOME=/usr/local/jdk1.8.0_202
   export SCALA_HOME=/usr/local/scala-2.11.0
   export HADOOP_HOME=/usr/local/hadoop-3.2.1
   export HADOOP_CONF_DIR=/usr/local/hadoop-3.2.1/etc/hadoop
   export SPARK_MASTER_IP=master
   export SPARK_WORKER_MEMORY=1g
   export SPARK_WORKER_CORES=1
   export SPARK_WORKER_INSTANCES=1
   ```

   

3. 配置slaves

   ```bash
   vim slaves
   #插入
   slave01
   slave02
   ```

   

4. 启动（注意指定spark启动，因为和hadoop文件相同）